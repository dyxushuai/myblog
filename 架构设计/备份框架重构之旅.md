本篇记录两次重构dbaas云服务备份模块的框架
# 初代架构
我接手这块代码时，架构比较简单，大概是这样的
```
#备份流程
手动/定时触发备份->单点的backup service 创建go协程执行备份

#恢复流程
手动触发恢复->单点的backup service 创建go协程执行恢复
```
其中go协程是异步的，避免了阻塞，备份状态记录在tidb，前端可以轮询。功能已经在线上运行了大半年，但随着客户数据越来越大，单点部署的backup service已经无法抗住所有客户实例的备份，重构迫在眉睫

# 第二代架构
openstack trove的备份架构非常简洁高效，因为backup service是部署在实例的虚拟机环境，一对一绑定，资源是绝对隔离的，相对于整个备份管理服务，不会存在单点的backup service，也绝对不会影响其他客户的实例，但是我们使用的是容器，无法做到虚拟机的隔离效果。

我也想过最快的改造方式，即多部署几个backup service，client端采用round robin的方式来分摊单点的问题。但延续这种架构存在另外几个硬伤：
- 需要手动停止备份任务的时候，无法定位到执行worker在哪个node工作
- 升级更新backup service时，所有的worker都被killed，状态都丢失了，导致任务状态难以维护，需要清理脏数据
- round robin无法保证worker均匀分布，任务数量无法有效限制，容易造成单点被写爆

所以，我想利用生产者-消费者模式来解决这个问题，所有的待执行任务进入队列里面，每个backup service针对自身硬件条件启动指定数目的worker，worker去消费队列里面的任务，所以架构变成这个样子：

![image.png](https://github.com/jwongzblog/myblog/blob/master/image/backup_queue.png)

worker的行为：
- worker启动定时器去消费队列
- lock住这个task，并将相关信息cache到内存，worker的另一个协程去定时查看自身正在执行的task是否需要停止
- worker定时更新task的heartbeat，超过10分钟没有更新则标注失败

这样一来就可以无顾忌的横向扩展worker节点。

# 第三代架构
技术发展的停滞往往是本身满足于现状，好比之前大陆被嘲笑支付需要用手机，站在他们的角度来讲，他们一张轻巧的信用卡能解决所有问题，而我们手机的普及度远大于信用卡。我们互联网的高并发处理技术大概率已经超越灯塔国，当然也很有可能因为人口红利而止步，停止迭代

前两代的架构最大的缺陷是无法对task的绝对掌控，虽然性能、并发满足了，但是运营提出的节约成本的需求没法满足。我们的备份数据先dump到SSD、NVME这类高速介质，最后存储在ufile上（ucloud的对象存储，三副本高可靠高可用，流量消耗也比较大），最牛逼的客户的SQL实例已经达到8TB，太费成本。而实例本身是高可用高可靠，对备份的要求其实没那么高频，所以完全可以选择保留至冷存储。如果VIP客户需要备份数据也高可用高可靠，框架也能支持。那么我们需要对备份所分配的node资源严格可控。

上面的需求落实下来，备份task和kubernetes pod的生命周期非常相似，kubernetes是一个非常好的参考对象。

kubernetes中controller、scheduler、kubelet对于pod管理的设计思想可以提炼出来，完美的移植过来：
- node controller负责收集node的健康状态、资源、地址、名称等，resource controller负责处理node的额度
- scheduler创建pod时，针对分配规则选择最合适的node，然后通知kubelet去执行剩余创建动作
- kubelet运行在node上，负责pod的创建、容器的创建，监控等

![image.png](https://github.com/jwongzblog/myblog/blob/master/image/kube_resource.png)

重构后，最后的架构变成这个样子：
- controller负责收集node信息（健康、空间、执行的任务数、磁盘io、内存、cpu负载）
- scheduler接受到创建备份请求后开始匹配最合适的node，通知这个node的backup-worker
- backup-worker执行备份，更新heartbeat
