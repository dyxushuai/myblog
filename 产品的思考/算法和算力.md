过去几年，一个显而易见的科技趋势就是大数据，按李彦宏的说法，他当年在美国留学的时候，机器学习算法已经趋于完善，但是那些教授光有理论，而缺乏有效的工程手段让机器学习产生价值。随后，谷歌放出来的map-reduce、bigtable等论文，但是没开源内部实践多年算力系统。不过开源界的大牛根们据谷歌的论文开发出一套一套算力系统，一下子推动了人类进入大数据时代。
IT圈的各个角落都尝试把握这个趋势，解决其中任何环节的问题，都能赚上一笔
- 有的判断大数据时代需要大量的物理设备，所以建了大量的数据中心用来出租。
- 有的判断大数据时代还需要更优秀的算法，所以高薪圈养了一批批AI科学家。
- 有的判断这个工程过于浩大，不利于小团队创新，所以不停的完善一键式工具，让小团队专注创新。
- 有的判断自己无法搞定算法和基础设施，所以专注于行业领域，结合行业知识和已有的机器学习算法，解决最后一公里的创新
- ......

但是作为非大数据原住民程序员，我们又如何把握这个趋势？几年前，我把大数据时代要解决的问题拆成三个方面：
- 最难啃的是算法，这个要靠老天爷赏饭吃，没那个智商和时间的沉淀很难突破
- 次一级难啃的是算法+行业领域创新，这个不需要开发算法，但是需要懂算法，另外需要在一个行业积累足够的领域知识
- 解决算力问题，虽然我看不懂怎么解决，但是我感觉自己努力一下还是能够得着，混口饭应该没问题，所以我放弃了很多预期，加入了一家公有云玩家

两年过去了，我又有一些更细的想法：
##### 算法
我们可能过于乐观了，机器学习中神经网络一派脱颖而出，发展出深度学习一脉，卷积神经网络一招鲜，但是这些算法解决的场景有限，离我们在电影里面看到的强人工智能还非常远。撇开科幻式的想象，我们现在还在追求有限的场景中的正确率问题。
##### 分布式机器学习算法
教授的理论是解决做什么的问题，但是工程需要解决怎么做的问题，工程中如何让算法变成分布式可并行的处理，是非常关键的，串行的算法效率低下，搞学术的可以不管这些
##### 如何提供更强大的算力？

- 优秀的计算资源管理。我在这里就不讨论openstack和k8ts谁先进，可以肯定的是，和Google算法配套的borg系统延伸出来的k8ts从一开始就是一个颠覆者。
- 更快的吞吐。尝试打破传统计算机模型的设计，减少数据流通层次，以RDMA及DPDK为代表的新技术让程序员的socket编程变得落后。
- 更快的落盘。Google开源了levelDB，其LSM算法更适合大数据量的写入，后面出现的influxDB等时序数据库也引入了LSM算法。以SPDK为代表的Nvme优化，直接在用户态调用Nvme驱动，减少内核中断对数据落盘的影响。
- 更小的存储量。Cassandra、beringei、rocksDB等都用到了压缩算法
- cache。newsql尝试充分利用内存来加快数据读写，ceph这类分布式存储也尝试使用更快的硬件作为cache层，加快读写
- 冗余。数据的可用性尤其重要，解决手段也有限，基本上是多副本或者纠删码。前者又衍生出各种一致性算法。
- 并发。由于Google的bigtable产品只开源了levelDB，但是这玩意是单机版的，无法解决并发和冗余的问题，以TiDB为代表的bigtable开源系统试图填补这一空白。

作为非大数据原住民程序员的我只能想办法解决算力问题，而且优化没有上限，这种微创新的机会和成就感，是我前进的动力，学无止境，创新无止境。